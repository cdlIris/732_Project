{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5) # make sure we have Python 3.5+\n",
    "import re\n",
    "import math\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, SQLTransformer\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor,DecisionTreeRegressor,GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.appName('example code').getOrCreate()\n",
    "assert spark.version >= '2.4' # make sure we have Spark 2.4+\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set('spark.sql.session.timeZone', 'UTC')\n",
    "\n",
    "bitcoin_schema = types.StructType([\n",
    "    types.StructField('Date', types.StringType()),\n",
    "    types.StructField('Symbol', types.StringType()),\n",
    "    types.StructField('Open', types.FloatType()),\n",
    "    types.StructField('High', types.FloatType()),\n",
    "    types.StructField('Low', types.FloatType()),\n",
    "    types.StructField('Close', types.FloatType()),\n",
    "    types.StructField('Volume BTC', types.FloatType()),\n",
    "    types.StructField('Volume USD', types.FloatType()),\n",
    "])\n",
    "tweets_schema = types.StructType([\n",
    "    types.StructField('Date', types.StringType()),\n",
    "    types.StructField('tweet', types.StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\"timestamp\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume BTC\", \"Volume USD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+-------+-------+----------+----------+\n",
      "|          timestamp|   Open|   High|    Low|  Close|Volume BTC|Volume USD|\n",
      "+-------------------+-------+-------+-------+-------+----------+----------+\n",
      "|2017-07-01 11:00:00| 2562.3|2580.99| 2554.0| 2568.0|      3.04|   7781.15|\n",
      "|2017-07-01 12:00:00| 2568.0|2577.79|2555.01|2576.58|      11.0|  28231.42|\n",
      "|2017-07-01 13:00:00|2576.58|2576.58|2555.01|2555.08|     14.23|  36482.36|\n",
      "+-------------------+-------+-------+-------+-------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bitcoin_df = spark.read.csv(\"bitcoin-usd-hour.csv\", schema=bitcoin_schema).cache()\n",
    "bitcoin_df = bitcoin_df.withColumn(\"timestamp\", functions.unix_timestamp(\"Date\", 'yyyy-MM-dd hh-aa').cast(\"timestamp\")).drop('Date')\n",
    "bitcoin_df = bitcoin_df.select(col_order).sort(\"timestamp\").cache()\n",
    "bitcoin_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|          timestamp|               tweet|\n",
      "+-------------------+--------------------+\n",
      "|2019-11-17 00:00:01|b'Bitcoin - BTC\\n...|\n",
      "|2019-11-17 00:00:01|b'#HourlyCryptoSt...|\n",
      "|2019-11-17 00:00:02|\"b\"\"Join 'The Sig...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_df = spark.read.csv(\"tweets_history.csv\", schema=tweets_schema)\n",
    "tweet_df = tweet_df.withColumn(\"timestamp\", functions.unix_timestamp(\"Date\", 'yyyy-MM-dd HH:mm:ss').cast(\"timestamp\")).drop('Date')\n",
    "tweet_df = tweet_df.select(\"timestamp\", \"tweet\").sort(\"timestamp\").cache()\n",
    "tweet_df = tweet_df.na.drop()\n",
    "\n",
    "tweet_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'udf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7e564fb77999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfunc_udf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_udf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mCleanDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CleanedTweets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mCleanDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'udf' is not defined"
     ]
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "def function_udf(input_str):\n",
    "    input_str = re.sub(r'b', '', input_str)\n",
    "    p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION)\n",
    "    input_str = p.clean(input_str)\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", input_str).split())\n",
    "func_udf = udf(function_udf, StringType())\n",
    "CleanDF = tweet_df.withColumn('CleanedTweets', func_udf(tweet_df['tweet']))\n",
    "CleanDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
